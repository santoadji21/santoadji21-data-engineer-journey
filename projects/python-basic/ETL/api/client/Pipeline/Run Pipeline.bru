meta {
  name: Run Pipeline
  type: http
  seq: 1
}

post {
  url: {{base_url}}/pipeline/run
  body: none
  auth: none
}

docs {
  # Trigger ETL Pipeline
  Triggers the full ETL pipeline: Scrape → Clean → Load.

  **Pipeline steps:**
  1. **Extract** — scrape quotes from quotes.toscrape.com (or use cached data)
  2. **Transform** — clean text, deduplicate, enrich with word count and tags
  3. **Load** — save to Parquet + DuckDB + JSON

  **Expected Response (success):**
  ```json
  {
    "status": "success",
    "message": "Pipeline completed successfully",
    "rows_processed": 100,
    "output_file": "ETL/output/quotes.parquet"
  }
  ```

  **Note:** This may take 10-15 seconds on first run (scraping).
  Subsequent runs use cached data if < 1 hour old.
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 — SQL Analytics with DuckDB\n",
    "\n",
    "**DuckDB** is an in-process OLAP database — like SQLite, but optimized for **analytics**.  \n",
    "It runs SQL directly on CSV files, Parquet files, and Pandas DataFrames with zero setup.\n",
    "\n",
    "### What you'll learn\n",
    "| # | Topic | Key Takeaway |\n",
    "|---|-------|--------------|\n",
    "| 1 | **Setup** | Initialize DuckDB in-memory and persistent modes |\n",
    "| 2 | **CSV Ingestion** | Load large CSVs with `read_csv_auto`, schema inference |\n",
    "| 3 | **Query DataFrames** | Run SQL directly on Pandas DataFrames (zero copy!) |\n",
    "| 4 | **Query Files** | Run SQL on CSV/Parquet files without loading into memory |\n",
    "| 5 | **Parquet Integration** | Seamlessly move data between DuckDB and Parquet |\n",
    "| 6 | **OLAP Features** | Window functions, CTEs, complex aggregations |\n",
    "| 7 | **Export & Persist** | `COPY TO` CSV, save to a `.db` file |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup — Initializing DuckDB\n",
    "\n",
    "DuckDB can run **in-memory** (fast, temporary) or **persistent** (saved to a `.db` file).  \n",
    "No server needed — it runs inside your Python process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────┐\n",
      "│ duckdb_version │\n",
      "│    varchar     │\n",
      "├────────────────┤\n",
      "│ v1.4.4         │\n",
      "└────────────────┘\n",
      "\n",
      "\n",
      "DuckDB version: 1.4.4\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# ============================================================\n",
    "# 1a. In-Memory Connection\n",
    "# ============================================================\n",
    "# duckdb.connect() creates an in-memory database.\n",
    "# All data lives in RAM and is lost when the connection is closed.\n",
    "# Perfect for ad-hoc analytics and exploration.\n",
    "\n",
    "con = duckdb.connect()  # or duckdb.connect(':memory:') — same thing\n",
    "\n",
    "# Check DuckDB version\n",
    "result = con.sql(\"SELECT version() AS duckdb_version\")\n",
    "# con.sql() executes a SQL query and returns a DuckDBPyRelation object\n",
    "\n",
    "print(result)\n",
    "print(f\"\\nDuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetchall()  : [(42, 'hello')]\n",
      "fetchone()  : (42,)\n",
      "fetchdf()   :\n",
      "   answer greeting\n",
      "0      42    hello\n",
      "\n",
      "show():\n",
      "┌────────┬──────────┐\n",
      "│ answer │ greeting │\n",
      "│ int32  │ varchar  │\n",
      "├────────┼──────────┤\n",
      "│     42 │ hello    │\n",
      "└────────┴──────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1b. Basic SQL execution methods\n",
    "# ============================================================\n",
    "# DuckDB provides multiple ways to get results:\n",
    "\n",
    "# .sql() returns a relation (lazy — not executed until you fetch)\n",
    "rel = con.sql(\"SELECT 42 AS answer, 'hello' AS greeting\")\n",
    "\n",
    "# .fetchall() → list of tuples (raw Python)\n",
    "print(\"fetchall()  :\", rel.fetchall())\n",
    "\n",
    "# .fetchone() → single tuple (first row only)\n",
    "rel2 = con.sql(\"SELECT 42 AS answer\")\n",
    "print(\"fetchone()  :\", rel2.fetchone())\n",
    "\n",
    "# .fetchdf() → Pandas DataFrame (most useful for analysis)\n",
    "df_result = con.sql(\"SELECT 42 AS answer, 'hello' AS greeting\").fetchdf()\n",
    "# fetchdf() converts the result directly to a Pandas DataFrame\n",
    "print(\"fetchdf()   :\")\n",
    "print(df_result)\n",
    "\n",
    "# .show() → print formatted output to console (quick peek)\n",
    "print(\"\\nshow():\")\n",
    "con.sql(\"SELECT 42 AS answer, 'hello' AS greeting\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. CSV Ingestion — Loading Large CSVs\n",
    "\n",
    "DuckDB's `read_csv_auto` is extremely fast and auto-detects:  \n",
    "column names, data types, delimiters, date formats, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────────┬───────────┬───────────────────┬────────────────────┬──────────────────────────┬───────────────────────────┬─────────────────────────┬──────────────────────┬────────┬──────────┬────────┬─────────┬─────────┬────────────────┬──────────────────────┬───────────────────┬────────────────────────┬────────────────────────────────┬────────────────────┬────────────────────┬─────────────────┬──────────────┬────────┬─────────┬──────────────────────┬───────────────┬────────┬─────────────────────────────┬───────────────────────────┬────────────────────┬─────────────────────────┬────────────────┬─────────────────────────────┬──────────────┬──────────────────┐\n",
      "│    hotel     │ is_canceled │ lead_time │ arrival_date_year │ arrival_date_month │ arrival_date_week_number │ arrival_date_day_of_month │ stays_in_weekend_nights │ stays_in_week_nights │ adults │ children │ babies │  meal   │ country │ market_segment │ distribution_channel │ is_repeated_guest │ previous_cancellations │ previous_bookings_not_canceled │ reserved_room_type │ assigned_room_type │ booking_changes │ deposit_type │ agent  │ company │ days_in_waiting_list │ customer_type │  adr   │ required_car_parking_spaces │ total_of_special_requests │ reservation_status │ reservation_status_date │      name      │            email            │ phone-number │   credit_card    │\n",
      "│   varchar    │    int64    │   int64   │       int64       │      varchar       │          int64           │           int64           │          int64          │        int64         │ int64  │  double  │ int64  │ varchar │ varchar │    varchar     │       varchar        │       int64       │         int64          │             int64              │      varchar       │      varchar       │      int64      │   varchar    │ double │ double  │        int64         │    varchar    │ double │            int64            │           int64           │      varchar       │          date           │    varchar     │           varchar           │   varchar    │     varchar      │\n",
      "├──────────────┼─────────────┼───────────┼───────────────────┼────────────────────┼──────────────────────────┼───────────────────────────┼─────────────────────────┼──────────────────────┼────────┼──────────┼────────┼─────────┼─────────┼────────────────┼──────────────────────┼───────────────────┼────────────────────────┼────────────────────────────────┼────────────────────┼────────────────────┼─────────────────┼──────────────┼────────┼─────────┼──────────────────────┼───────────────┼────────┼─────────────────────────────┼───────────────────────────┼────────────────────┼─────────────────────────┼────────────────┼─────────────────────────────┼──────────────┼──────────────────┤\n",
      "│ Resort Hotel │           0 │       342 │              2015 │ July               │                       27 │                         1 │                       0 │                    0 │      2 │      0.0 │      0 │ BB      │ PRT     │ Direct         │ Direct               │                 0 │                      0 │                              0 │ C                  │ C                  │               3 │ No Deposit   │   NULL │    NULL │                    0 │ Transient     │    0.0 │                           0 │                         0 │ Check-Out          │ 2015-07-01              │ Ernest Barnes  │ Ernest.Barnes31@outlook.com │ 669-792-1661 │ ************4322 │\n",
      "│ Resort Hotel │           0 │       737 │              2015 │ July               │                       27 │                         1 │                       0 │                    0 │      2 │      0.0 │      0 │ BB      │ PRT     │ Direct         │ Direct               │                 0 │                      0 │                              0 │ C                  │ C                  │               4 │ No Deposit   │   NULL │    NULL │                    0 │ Transient     │    0.0 │                           0 │                         0 │ Check-Out          │ 2015-07-01              │ Andrea Baker   │ Andrea_Baker94@aol.com      │ 858-637-6955 │ ************9157 │\n",
      "│ Resort Hotel │           0 │         7 │              2015 │ July               │                       27 │                         1 │                       0 │                    1 │      1 │      0.0 │      0 │ BB      │ GBR     │ Direct         │ Direct               │                 0 │                      0 │                              0 │ A                  │ C                  │               0 │ No Deposit   │   NULL │    NULL │                    0 │ Transient     │   75.0 │                           0 │                         0 │ Check-Out          │ 2015-07-02              │ Rebecca Parker │ Rebecca_Parker@comcast.net  │ 652-885-2745 │ ************3734 │\n",
      "│ Resort Hotel │           0 │        13 │              2015 │ July               │                       27 │                         1 │                       0 │                    1 │      1 │      0.0 │      0 │ BB      │ GBR     │ Corporate      │ Corporate            │                 0 │                      0 │                              0 │ A                  │ A                  │               0 │ No Deposit   │  304.0 │    NULL │                    0 │ Transient     │   75.0 │                           0 │                         0 │ Check-Out          │ 2015-07-02              │ Laura Murray   │ Laura_M@gmail.com           │ 364-656-8427 │ ************5677 │\n",
      "│ Resort Hotel │           0 │        14 │              2015 │ July               │                       27 │                         1 │                       0 │                    2 │      2 │      0.0 │      0 │ BB      │ GBR     │ Online TA      │ TA/TO                │                 0 │                      0 │                              0 │ A                  │ A                  │               0 │ No Deposit   │  240.0 │    NULL │                    0 │ Transient     │   98.0 │                           0 │                         1 │ Check-Out          │ 2015-07-03              │ Linda Hines    │ LHines@verizon.com          │ 713-226-5883 │ ************5498 │\n",
      "└──────────────┴─────────────┴───────────┴───────────────────┴────────────────────┴──────────────────────────┴───────────────────────────┴─────────────────────────┴──────────────────────┴────────┴──────────┴────────┴─────────┴─────────┴────────────────┴──────────────────────┴───────────────────┴────────────────────────┴────────────────────────────────┴────────────────────┴────────────────────┴─────────────────┴──────────────┴────────┴─────────┴──────────────────────┴───────────────┴────────┴─────────────────────────────┴───────────────────────────┴────────────────────┴─────────────────────────┴────────────────┴─────────────────────────────┴──────────────┴──────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2a. read_csv_auto — auto-detect everything\n",
    "# ============================================================\n",
    "# read_csv_auto(path) reads a CSV with automatic schema inference.\n",
    "# DuckDB samples the file to guess types — much smarter than Pandas.\n",
    "\n",
    "# Quick peek at the CSV structure (first 5 rows)\n",
    "con.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('data/hotel_booking.csv')\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐\n",
      "│         column_name         │ column_type │  null   │   key   │ default │  extra  │\n",
      "│           varchar           │   varchar   │ varchar │ varchar │ varchar │ varchar │\n",
      "├─────────────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│ hotel                       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ is_canceled                 │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ lead_time                   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ arrival_date_year           │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ arrival_date_month          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ arrival_date_week_number    │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ arrival_date_day_of_month   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ stays_in_weekend_nights     │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ stays_in_week_nights        │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ adults                      │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│   ·                         │   ·         │  ·      │  ·      │  ·      │  ·      │\n",
      "│   ·                         │   ·         │  ·      │  ·      │  ·      │  ·      │\n",
      "│   ·                         │   ·         │  ·      │  ·      │  ·      │  ·      │\n",
      "│ customer_type               │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ adr                         │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ required_car_parking_spaces │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ total_of_special_requests   │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ reservation_status          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ reservation_status_date     │ DATE        │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ name                        │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ email                       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ phone-number                │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ credit_card                 │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "├─────────────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┤\n",
      "│ 36 rows (20 shown)                                                      6 columns │\n",
      "└───────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2b. Inspect auto-detected schema\n",
    "# ============================================================\n",
    "# DESCRIBE shows column names and inferred data types.\n",
    "# Useful for verifying DuckDB guessed correctly.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    DESCRIBE SELECT *\n",
    "    FROM read_csv_auto('data/hotel_booking.csv')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┐\n",
      "│ total_rows │\n",
      "│   int64    │\n",
      "├────────────┤\n",
      "│     119390 │\n",
      "└────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2c. CREATE TABLE from CSV — persist in DuckDB\n",
    "# ============================================================\n",
    "# CREATE TABLE AS SELECT (CTAS) loads CSV data into a DuckDB table.\n",
    "# Once loaded, queries run on DuckDB's optimized columnar format.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE bookings AS\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('data/hotel_booking.csv')\n",
    "\"\"\")\n",
    "# CREATE OR REPLACE → drop the table if it exists and recreate\n",
    "\n",
    "# Verify row count\n",
    "con.sql(\"SELECT COUNT(*) AS total_rows FROM bookings\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────┬────────┬───────────┐\n",
      "│    hotel     │ country │  adr   │ lead_time │\n",
      "│   varchar    │ varchar │ double │   int64   │\n",
      "├──────────────┼─────────┼────────┼───────────┤\n",
      "│ Resort Hotel │ PRT     │    0.0 │       342 │\n",
      "│ Resort Hotel │ PRT     │    0.0 │       737 │\n",
      "│ Resort Hotel │ GBR     │   75.0 │         7 │\n",
      "│ Resort Hotel │ GBR     │   75.0 │        13 │\n",
      "│ Resort Hotel │ GBR     │   98.0 │        14 │\n",
      "└──────────────┴─────────┴────────┴───────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2d. read_csv with explicit options\n",
    "# ============================================================\n",
    "# For full control, you can specify options manually:\n",
    "#   delim       : column separator (default: auto-detect)\n",
    "#   header      : True/False — does the file have a header row?\n",
    "#   columns     : dict of {name: type} for explicit schema\n",
    "#   nullstr     : string to interpret as NULL\n",
    "#   sample_size : rows to sample for type inference (default: -1 = all)\n",
    "\n",
    "# Example: read with explicit settings\n",
    "con.sql(\"\"\"\n",
    "    SELECT hotel, country, adr, lead_time\n",
    "    FROM read_csv(\n",
    "        'data/hotel_booking.csv',\n",
    "        delim = ',',\n",
    "        header = true,\n",
    "        nullstr = '',\n",
    "        auto_detect = true\n",
    "    )\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Query Pandas DataFrames — Zero Copy SQL\n",
    "\n",
    "DuckDB can query Pandas DataFrames **directly** by name — no loading or copying needed.  \n",
    "Just reference the Python variable name in your SQL `FROM` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (119390, 11)\n",
      "┌──────────────┬──────────┬─────────┐\n",
      "│    hotel     │ bookings │ avg_adr │\n",
      "│   varchar    │  int64   │ double  │\n",
      "├──────────────┼──────────┼─────────┤\n",
      "│ City Hotel   │    79330 │   105.3 │\n",
      "│ Resort Hotel │    40060 │   94.95 │\n",
      "└──────────────┴──────────┴─────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 3a. Query a DataFrame by variable name\n",
    "# ============================================================\n",
    "# Load a DataFrame with Pandas (as we did in notebook 04)\n",
    "df_hotel = pd.read_csv(\n",
    "    \"data/hotel_booking.csv\",\n",
    "    usecols=[\"hotel\", \"is_canceled\", \"lead_time\", \"country\", \"adr\",\n",
    "             \"arrival_date_year\", \"arrival_date_month\",\n",
    "             \"stays_in_weekend_nights\", \"stays_in_week_nights\",\n",
    "             \"reserved_room_type\", \"market_segment\"],\n",
    ")\n",
    "\n",
    "print(f\"DataFrame shape: {df_hotel.shape}\")\n",
    "\n",
    "# Now run SQL on the DataFrame — just use the variable name!\n",
    "# DuckDB automatically detects Python variables as virtual tables.\n",
    "con.sql(\"\"\"\n",
    "    SELECT hotel, COUNT(*) AS bookings, ROUND(AVG(adr), 2) AS avg_adr\n",
    "    FROM df_hotel\n",
    "    GROUP BY hotel\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country  total_bookings  cancellations  avg_adr  avg_lead_time\n",
      "    PRT           48590        27519.0    92.04          116.0\n",
      "    GBR           12129         2453.0    96.02          127.0\n",
      "    FRA           10415         1934.0   109.62           82.0\n",
      "    ESP            8568         2177.0   117.00           55.0\n",
      "    DEU            7287         1218.0   104.40          137.0\n",
      "    ITA            3766         1333.0   113.95           91.0\n",
      "    IRL            3375          832.0    98.19          120.0\n",
      "    BEL            2342          474.0   113.85          100.0\n",
      "    BRA            2224          830.0   111.01           83.0\n",
      "    NLD            2104          387.0   108.09           81.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3b. Complex query on DataFrame — filter, aggregate, sort\n",
    "# ============================================================\n",
    "\n",
    "result = con.sql(\"\"\"\n",
    "    SELECT\n",
    "        country,\n",
    "        COUNT(*) AS total_bookings,\n",
    "        SUM(CASE WHEN is_canceled = 1 THEN 1 ELSE 0 END) AS cancellations,\n",
    "        ROUND(AVG(adr), 2) AS avg_adr,\n",
    "        ROUND(AVG(lead_time), 0) AS avg_lead_time\n",
    "    FROM df_hotel\n",
    "    WHERE country IS NOT NULL\n",
    "    GROUP BY country\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY total_bookings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()  # fetchdf() converts result → Pandas DataFrame\n",
    "\n",
    "print(result.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────┬───────────────┬──────────┬─────────┐\n",
      "│  country_name  │   continent   │ bookings │ avg_adr │\n",
      "│    varchar     │    varchar    │  int64   │ double  │\n",
      "├────────────────┼───────────────┼──────────┼─────────┤\n",
      "│ Portugal       │ Europe        │    21071 │   90.34 │\n",
      "│ United Kingdom │ Europe        │     9676 │   90.47 │\n",
      "│ France         │ Europe        │     8481 │  105.75 │\n",
      "│ Spain          │ Europe        │     6391 │   110.3 │\n",
      "│ Germany        │ Europe        │     6069 │  101.26 │\n",
      "│ Ireland        │ Europe        │     2543 │   94.69 │\n",
      "│ Italy          │ Europe        │     2433 │  110.76 │\n",
      "│ Netherlands    │ Europe        │     1717 │  105.01 │\n",
      "│ United States  │ North America │     1596 │  118.98 │\n",
      "│ Brazil         │ South America │     1394 │   107.6 │\n",
      "├────────────────┴───────────────┴──────────┴─────────┤\n",
      "│ 10 rows                                   4 columns │\n",
      "└─────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3c. Join DataFrames with SQL\n",
    "# ============================================================\n",
    "# You can join multiple DataFrames together using SQL.\n",
    "\n",
    "# Create a dimension DataFrame\n",
    "df_countries = pd.DataFrame({\n",
    "    \"code\": [\"PRT\", \"GBR\", \"FRA\", \"ESP\", \"DEU\", \"ITA\", \"BRA\", \"USA\", \"NLD\", \"IRL\"],\n",
    "    \"country_name\": [\"Portugal\", \"United Kingdom\", \"France\", \"Spain\",\n",
    "                     \"Germany\", \"Italy\", \"Brazil\", \"United States\",\n",
    "                     \"Netherlands\", \"Ireland\"],\n",
    "    \"continent\": [\"Europe\", \"Europe\", \"Europe\", \"Europe\",\n",
    "                  \"Europe\", \"Europe\", \"South America\", \"North America\",\n",
    "                  \"Europe\", \"Europe\"],\n",
    "})\n",
    "\n",
    "# SQL JOIN across two DataFrames — just use their variable names\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        c.country_name,\n",
    "        c.continent,\n",
    "        COUNT(*) AS bookings,\n",
    "        ROUND(AVG(h.adr), 2) AS avg_adr\n",
    "    FROM df_hotel h\n",
    "    JOIN df_countries c ON h.country = c.code\n",
    "    WHERE h.is_canceled = 0\n",
    "    GROUP BY c.country_name, c.continent\n",
    "    ORDER BY bookings DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Query Files Directly — No Loading Required\n",
    "\n",
    "DuckDB can run SQL directly on **CSV and Parquet files** on disk.  \n",
    "The file is never fully loaded into memory — DuckDB streams and processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬───────┬──────────┬───────────────┐\n",
      "│    hotel     │ year  │ bookings │ total_revenue │\n",
      "│   varchar    │ int64 │  int64   │    double     │\n",
      "├──────────────┼───────┼──────────┼───────────────┤\n",
      "│ City Hotel   │  2015 │     7678 │    1894323.54 │\n",
      "│ City Hotel   │  2016 │    22733 │     6862128.0 │\n",
      "│ City Hotel   │  2017 │    15817 │    5637958.64 │\n",
      "│ Resort Hotel │  2015 │     6176 │    2617235.57 │\n",
      "│ Resort Hotel │  2016 │    13637 │    4811373.43 │\n",
      "│ Resort Hotel │  2017 │     9125 │    4173241.23 │\n",
      "└──────────────┴───────┴──────────┴───────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4a. Query CSV file directly\n",
    "# ============================================================\n",
    "# Just put the file path in read_csv_auto() inside the FROM clause.\n",
    "# No CREATE TABLE, no pd.read_csv — straight to results.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        hotel,\n",
    "        arrival_date_year AS year,\n",
    "        COUNT(*) AS bookings,\n",
    "        ROUND(SUM(adr * (stays_in_weekend_nights + stays_in_week_nights)), 2) AS total_revenue\n",
    "    FROM read_csv_auto('data/hotel_booking.csv')\n",
    "    WHERE is_canceled = 0\n",
    "    GROUP BY hotel, arrival_date_year\n",
    "    ORDER BY hotel, year\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV size     : 23.95 MB\n",
      "Parquet size : 5.11 MB\n",
      "Compression  : 4.7x smaller\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4b. Query Parquet file directly\n",
    "# ============================================================\n",
    "# First, create a Parquet file from the CSV (if not already done in notebook 04)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"data/output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "parquet_path = output_dir / \"hotel_bookings.parquet\"\n",
    "\n",
    "# Use DuckDB itself to convert CSV → Parquet (fast!)\n",
    "# COPY ... TO ... writes query results to a file.\n",
    "con.sql(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_csv_auto('data/hotel_booking.csv')\n",
    "    )\n",
    "    TO '{parquet_path}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY)\n",
    "\"\"\")\n",
    "# FORMAT PARQUET  → output format\n",
    "# COMPRESSION SNAPPY → fast compression algorithm\n",
    "\n",
    "csv_size = Path(\"data/hotel_booking.csv\").stat().st_size / 1024**2\n",
    "pq_size = parquet_path.stat().st_size / 1024**2\n",
    "print(f\"CSV size     : {csv_size:.2f} MB\")\n",
    "print(f\"Parquet size : {pq_size:.2f} MB\")\n",
    "print(f\"Compression  : {csv_size / pq_size:.1f}x smaller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────┬──────────┬─────────┬───────────────┐\n",
      "│    hotel     │  room   │ bookings │ avg_adr │ avg_lead_days │\n",
      "│   varchar    │ varchar │  int64   │ double  │    double     │\n",
      "├──────────────┼─────────┼──────────┼─────────┼───────────────┤\n",
      "│ City Hotel   │ A       │    34529 │   98.84 │          85.0 │\n",
      "│ City Hotel   │ D       │     7513 │  129.93 │          72.0 │\n",
      "│ City Hotel   │ F       │     1060 │  190.53 │          67.0 │\n",
      "│ City Hotel   │ E       │     1011 │  159.03 │          59.0 │\n",
      "│ City Hotel   │ B       │      717 │   91.01 │         109.0 │\n",
      "│ City Hotel   │ G       │      313 │  226.58 │          55.0 │\n",
      "│ City Hotel   │ C       │        6 │  102.17 │          98.0 │\n",
      "│ Resort Hotel │ A       │    16567 │   75.81 │          76.0 │\n",
      "│ Resort Hotel │ D       │     5406 │   101.4 │          92.0 │\n",
      "│ Resort Hotel │ E       │     3511 │  110.92 │          91.0 │\n",
      "│ Resort Hotel │ G       │      937 │  164.71 │          68.0 │\n",
      "│ Resort Hotel │ F       │      891 │  133.81 │          54.0 │\n",
      "│ Resort Hotel │ C       │      601 │  157.86 │          70.0 │\n",
      "│ Resort Hotel │ H       │      350 │  183.97 │          53.0 │\n",
      "│ Resort Hotel │ L       │        4 │   151.0 │           0.0 │\n",
      "│ Resort Hotel │ B       │        3 │  104.67 │           8.0 │\n",
      "├──────────────┴─────────┴──────────┴─────────┴───────────────┤\n",
      "│ 16 rows                                           5 columns │\n",
      "└─────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now query the Parquet file directly — even faster than CSV\n",
    "# read_parquet() or just the file path with a .parquet extension\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "    SELECT\n",
    "        hotel,\n",
    "        reserved_room_type AS room,\n",
    "        COUNT(*) AS bookings,\n",
    "        ROUND(AVG(adr), 2) AS avg_adr,\n",
    "        ROUND(AVG(lead_time), 0) AS avg_lead_days\n",
    "    FROM read_parquet('{parquet_path}')\n",
    "    WHERE is_canceled = 0\n",
    "      AND adr > 0\n",
    "    GROUP BY hotel, reserved_room_type\n",
    "    ORDER BY hotel, bookings DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┐\n",
      "│ total_rows │\n",
      "│   int64    │\n",
      "├────────────┤\n",
      "│     119390 │\n",
      "└────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4c. Glob patterns — query multiple files at once\n",
    "# ============================================================\n",
    "# DuckDB supports glob patterns to query many files as one table.\n",
    "# Useful for: partitioned datasets, daily batch files.\n",
    "#\n",
    "# read_csv_auto('data/output/*.csv')   → all CSVs in the folder\n",
    "# read_parquet('data/year=*/data.parquet') → Hive-partitioned parquet\n",
    "\n",
    "# Query ALL Parquet files in output/ as if they were one table\n",
    "con.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS total_rows\n",
    "    FROM read_parquet('data/output/*.parquet')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Parquet Integration — DuckDB as a Parquet Engine\n",
    "\n",
    "DuckDB reads and writes Parquet natively. It can also inspect Parquet metadata  \n",
    "and perform **column pruning** (read only needed columns from Parquet files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬────────────────────┬─────────────────┐\n",
      "│ row_group_id │ row_group_num_rows │ row_group_bytes │\n",
      "│    int64     │       int64        │      int64      │\n",
      "├──────────────┼────────────────────┼─────────────────┤\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            · │                ·   │            ·    │\n",
      "│            · │                ·   │            ·    │\n",
      "│            · │                ·   │            ·    │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "│            0 │             119390 │         9350169 │\n",
      "├──────────────┴────────────────────┴─────────────────┤\n",
      "│ 36 rows (20 shown)                        3 columns │\n",
      "└─────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5a. Inspect Parquet metadata from SQL\n",
    "# ============================================================\n",
    "# parquet_metadata() reads the Parquet file footer — no data loaded.\n",
    "# Shows: row groups, row count, total size, etc.\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "    SELECT\n",
    "        row_group_id,\n",
    "        row_group_num_rows,\n",
    "        row_group_bytes\n",
    "    FROM parquet_metadata('{parquet_path}')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────────┬────────────┬────────────────┐\n",
      "│           name            │    type    │ converted_type │\n",
      "│          varchar          │  varchar   │    varchar     │\n",
      "├───────────────────────────┼────────────┼────────────────┤\n",
      "│ duckdb_schema             │ NULL       │ NULL           │\n",
      "│ hotel                     │ BYTE_ARRAY │ UTF8           │\n",
      "│ is_canceled               │ INT64      │ INT_64         │\n",
      "│ lead_time                 │ INT64      │ INT_64         │\n",
      "│ arrival_date_year         │ INT64      │ INT_64         │\n",
      "│ arrival_date_month        │ BYTE_ARRAY │ UTF8           │\n",
      "│ arrival_date_week_number  │ INT64      │ INT_64         │\n",
      "│ arrival_date_day_of_month │ INT64      │ INT_64         │\n",
      "│ stays_in_weekend_nights   │ INT64      │ INT_64         │\n",
      "│ stays_in_week_nights      │ INT64      │ INT_64         │\n",
      "│ adults                    │ INT64      │ INT_64         │\n",
      "│ children                  │ DOUBLE     │ NULL           │\n",
      "│ babies                    │ INT64      │ INT_64         │\n",
      "│ meal                      │ BYTE_ARRAY │ UTF8           │\n",
      "│ country                   │ BYTE_ARRAY │ UTF8           │\n",
      "├───────────────────────────┴────────────┴────────────────┤\n",
      "│ 15 rows                                       3 columns │\n",
      "└─────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5b. Inspect Parquet schema\n",
    "# ============================================================\n",
    "# parquet_schema() shows column names, types, and compression.\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "    SELECT name, type, converted_type\n",
    "    FROM parquet_schema('{parquet_path}')\n",
    "    LIMIT 15\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┐\n",
      "│  rows  │\n",
      "│ int64  │\n",
      "├────────┤\n",
      "│ 117429 │\n",
      "└────────┘\n",
      "\n",
      "Clean Parquet: 0.59 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5c. Parquet → DuckDB Table → Parquet round-trip\n",
    "# ============================================================\n",
    "# Load Parquet into a table, transform, export back to Parquet.\n",
    "# A common ETL pattern: raw.parquet → transform → clean.parquet\n",
    "\n",
    "# Step 1: Load from Parquet into a table\n",
    "con.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE hotel_clean AS\n",
    "    SELECT\n",
    "        hotel,\n",
    "        country,\n",
    "        CAST(adr AS FLOAT) AS adr,\n",
    "        -- CAST(value AS type) converts a value to a specific SQL data type\n",
    "        (stays_in_weekend_nights + stays_in_week_nights) AS total_nights,\n",
    "        adr * (stays_in_weekend_nights + stays_in_week_nights) AS total_revenue,\n",
    "        arrival_date_year AS year,\n",
    "        arrival_date_month AS month,\n",
    "        reserved_room_type AS room_type,\n",
    "        market_segment,\n",
    "        is_canceled\n",
    "    FROM read_parquet('{parquet_path}')\n",
    "    WHERE adr > 0\n",
    "      AND adr < 5000   -- remove outliers\n",
    "\"\"\")\n",
    "\n",
    "con.sql(\"SELECT COUNT(*) AS rows FROM hotel_clean\").show()\n",
    "\n",
    "# Step 2: Export the cleaned table back to Parquet\n",
    "clean_parquet = output_dir / \"hotel_clean.parquet\"\n",
    "con.sql(f\"\"\"\n",
    "    COPY hotel_clean\n",
    "    TO '{clean_parquet}'\n",
    "    (FORMAT PARQUET, COMPRESSION ZSTD)\n",
    "\"\"\")\n",
    "# COMPRESSION ZSTD → Zstandard: better ratio than Snappy, nearly as fast\n",
    "\n",
    "print(f\"Clean Parquet: {clean_parquet.stat().st_size / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. OLAP Features — Window Functions & Advanced SQL\n",
    "\n",
    "Window functions perform calculations **across rows** related to the current row,  \n",
    "without collapsing them into a single output row (unlike GROUP BY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────┬──────────┬─────────┬───────┐\n",
      "│    hotel     │ country │ bookings │ avg_adr │ rank  │\n",
      "│   varchar    │ varchar │  int64   │ double  │ int64 │\n",
      "├──────────────┼─────────┼──────────┼─────────┼───────┤\n",
      "│ City Hotel   │ PRT     │     9993 │   98.17 │     1 │\n",
      "│ City Hotel   │ FRA     │     7042 │   109.1 │     2 │\n",
      "│ City Hotel   │ DEU     │     4982 │  107.04 │     3 │\n",
      "│ City Hotel   │ GBR     │     3737 │  112.64 │     4 │\n",
      "│ City Hotel   │ ESP     │     3255 │  110.83 │     5 │\n",
      "│ Resort Hotel │ PRT     │     9715 │   94.97 │     1 │\n",
      "│ Resort Hotel │ GBR     │     5867 │   77.46 │     2 │\n",
      "│ Resort Hotel │ ESP     │     3058 │  112.55 │     3 │\n",
      "│ Resort Hotel │ IRL     │     1729 │   86.76 │     4 │\n",
      "│ Resort Hotel │ FRA     │     1386 │    92.8 │     5 │\n",
      "├──────────────┴─────────┴──────────┴─────────┴───────┤\n",
      "│ 10 rows                                   5 columns │\n",
      "└─────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6a. ROW_NUMBER — assign sequential IDs within partitions\n",
    "# ============================================================\n",
    "# ROW_NUMBER() OVER (PARTITION BY ... ORDER BY ...)\n",
    "#   PARTITION BY → groups rows (like GROUP BY but keeps all rows)\n",
    "#   ORDER BY     → determines numbering order within each partition\n",
    "#\n",
    "# Use case: find the top-N items per group.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    WITH ranked AS (\n",
    "        -- CTE (Common Table Expression): a named temporary result set\n",
    "        -- WITH name AS (query) makes complex queries readable\n",
    "        SELECT\n",
    "            hotel,\n",
    "            country,\n",
    "            COUNT(*) AS bookings,\n",
    "            ROUND(AVG(adr), 2) AS avg_adr,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY hotel     -- restart numbering for each hotel\n",
    "                ORDER BY COUNT(*) DESC -- rank by most bookings first\n",
    "            ) AS rank\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY hotel, country\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM ranked\n",
    "    WHERE rank <= 5   -- top 5 countries per hotel\n",
    "    ORDER BY hotel, rank\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬───────────┬────────────────────┬────────────────────┐\n",
      "│ year  │   month   │  monthly_revenue   │   running_total    │\n",
      "│ int64 │  varchar  │       double       │       double       │\n",
      "├───────┼───────────┼────────────────────┼────────────────────┤\n",
      "│  2016 │ January   │  264521.3800000002 │  748692.1000000006 │\n",
      "│  2016 │ February  │  484170.7200000003 │  484170.7200000003 │\n",
      "│  2016 │ December  │  657870.7199999993 │  9455423.420000004 │\n",
      "│  2016 │ November  │  688843.4699999993 │  7725450.860000007 │\n",
      "│  2016 │ March     │  767337.4199999995 │         1516029.52 │\n",
      "│  2016 │ April     │   896591.380000001 │  7036607.390000008 │\n",
      "│  2016 │ October   │ 1072101.8399999987 │  8797552.700000005 │\n",
      "│  2016 │ May       │  1073277.629999999 │ 11673501.430000002 │\n",
      "│  2016 │ June      │ 1144800.3799999994 │ 10600223.800000003 │\n",
      "│  2016 │ September │ 1289642.6900000002 │  4614996.960000005 │\n",
      "│  2016 │ July      │  1525019.050000003 │  6140016.010000007 │\n",
      "│  2016 │ August    │ 1809324.7500000042 │  3325354.270000004 │\n",
      "├───────┴───────────┴────────────────────┴────────────────────┤\n",
      "│ 12 rows                                           4 columns │\n",
      "└─────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6b. Running Totals — SUM OVER with window frame\n",
    "# ============================================================\n",
    "# SUM() OVER (ORDER BY ...) computes a cumulative/running total.\n",
    "#   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW → running total\n",
    "#   This is the DEFAULT frame for ORDER BY, so it's often omitted.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        year,\n",
    "        month,\n",
    "        SUM(total_revenue) AS monthly_revenue,\n",
    "        SUM(SUM(total_revenue)) OVER (\n",
    "            PARTITION BY year\n",
    "            ORDER BY MIN(total_revenue)  -- rough month ordering\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS running_total\n",
    "    FROM hotel_clean\n",
    "    WHERE is_canceled = 0\n",
    "      AND year = 2016\n",
    "    GROUP BY year, month\n",
    "    ORDER BY monthly_revenue\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬─────────────┬──────────┬───────────────────┬────────────────┐\n",
      "│ year  │   revenue   │ bookings │ prev_year_revenue │ yoy_growth_pct │\n",
      "│ int64 │   double    │  int64   │      double       │     double     │\n",
      "├───────┼─────────────┼──────────┼───────────────────┼────────────────┤\n",
      "│  2015 │  4511559.11 │    13337 │              NULL │           NULL │\n",
      "│  2016 │ 11673501.43 │    35544 │        4511559.11 │          158.7 │\n",
      "│  2017 │  9811263.67 │    24538 │       11673501.43 │          -16.0 │\n",
      "└───────┴─────────────┴──────────┴───────────────────┴────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6c. LAG / LEAD — access previous / next row values\n",
    "# ============================================================\n",
    "# LAG(column, offset, default) → value from N rows BEFORE\n",
    "# LEAD(column, offset, default) → value from N rows AFTER\n",
    "#\n",
    "# Use case: compare current value vs. previous period (MoM, YoY).\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    WITH yearly AS (\n",
    "        SELECT\n",
    "            year,\n",
    "            ROUND(SUM(total_revenue), 2) AS revenue,\n",
    "            COUNT(*) AS bookings\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY year\n",
    "    )\n",
    "    SELECT\n",
    "        year,\n",
    "        revenue,\n",
    "        bookings,\n",
    "        LAG(revenue, 1) OVER (ORDER BY year) AS prev_year_revenue,\n",
    "        -- LAG(revenue, 1) looks 1 row back ordered by year\n",
    "        ROUND(\n",
    "            (revenue - LAG(revenue, 1) OVER (ORDER BY year))\n",
    "            / LAG(revenue, 1) OVER (ORDER BY year) * 100,\n",
    "            1\n",
    "        ) AS yoy_growth_pct\n",
    "        -- Year-over-Year growth percentage\n",
    "    FROM yearly\n",
    "    ORDER BY year\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬────────────────┬─────────┬───────┬──────────────┐\n",
      "│ country │ total_bookings │ avg_adr │ rank  │ adr_quartile │\n",
      "│ varchar │     int64      │ double  │ int64 │    int64     │\n",
      "├─────────┼────────────────┼─────────┼───────┼──────────────┤\n",
      "│ PRT     │          19708 │   96.59 │     1 │            1 │\n",
      "│ GBR     │           9604 │   91.15 │     2 │            1 │\n",
      "│ FRA     │           8428 │  106.42 │     3 │            3 │\n",
      "│ ESP     │           6313 │  111.67 │     4 │            4 │\n",
      "│ DEU     │           6028 │  101.95 │     5 │            1 │\n",
      "│ IRL     │           2537 │   94.91 │     6 │            1 │\n",
      "│ ITA     │           2417 │  111.49 │     7 │            3 │\n",
      "│ BEL     │           1862 │  111.84 │     8 │            4 │\n",
      "│ NLD     │           1713 │  105.26 │     9 │            2 │\n",
      "│ USA     │           1586 │  119.73 │    10 │            4 │\n",
      "├─────────┴────────────────┴─────────┴───────┴──────────────┤\n",
      "│ 10 rows                                         5 columns │\n",
      "└───────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6d. RANK and NTILE — ranking and bucketing\n",
    "# ============================================================\n",
    "# RANK()    → rank with gaps (1, 2, 2, 4)\n",
    "# DENSE_RANK() → rank without gaps (1, 2, 2, 3)\n",
    "# NTILE(n)  → split rows into N equal-sized buckets (quartiles, deciles...)\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        country,\n",
    "        total_bookings,\n",
    "        avg_adr,\n",
    "        RANK() OVER (ORDER BY total_bookings DESC) AS rank,\n",
    "        NTILE(4) OVER (ORDER BY avg_adr) AS adr_quartile\n",
    "        -- NTILE(4) splits all rows into 4 equal buckets by avg_adr\n",
    "        -- Quartile 1 = lowest ADR, Quartile 4 = highest ADR\n",
    "    FROM (\n",
    "        SELECT\n",
    "            country,\n",
    "            COUNT(*) AS total_bookings,\n",
    "            ROUND(AVG(adr), 2) AS avg_adr\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY country\n",
    "        HAVING COUNT(*) > 500\n",
    "    )\n",
    "    ORDER BY rank\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬───────────┬──────────┬─────────┬───────────────┬─────────────────┬──────────────┐\n",
      "│    hotel     │ room_type │ bookings │ avg_adr │ total_revenue │ avg_stay_nights │ pct_of_hotel │\n",
      "│   varchar    │  varchar  │  int64   │ double  │    double     │     double      │    double    │\n",
      "├──────────────┼───────────┼──────────┼─────────┼───────────────┼─────────────────┼──────────────┤\n",
      "│ City Hotel   │ A         │    34529 │   98.84 │     9632688.5 │             2.8 │         76.5 │\n",
      "│ City Hotel   │ D         │     7513 │  129.93 │    3221588.26 │             3.4 │         16.6 │\n",
      "│ City Hotel   │ F         │     1060 │  190.53 │     580745.11 │             2.9 │          2.3 │\n",
      "│ City Hotel   │ E         │     1011 │  159.03 │     509744.91 │             3.2 │          2.2 │\n",
      "│ City Hotel   │ G         │      313 │  226.58 │      234582.3 │             3.3 │          0.7 │\n",
      "│ City Hotel   │ B         │      717 │   91.01 │      212992.1 │             3.3 │          1.6 │\n",
      "│ Resort Hotel │ A         │    16567 │   75.81 │    4880164.17 │             3.7 │         58.6 │\n",
      "│ Resort Hotel │ D         │     5406 │   101.4 │    2825399.82 │             5.2 │         19.1 │\n",
      "│ Resort Hotel │ E         │     3511 │  110.92 │     1996547.1 │             5.1 │         12.4 │\n",
      "│ Resort Hotel │ G         │      937 │  164.71 │     653642.29 │             4.2 │          3.3 │\n",
      "│ Resort Hotel │ F         │      891 │  133.81 │     564810.76 │             4.4 │          3.2 │\n",
      "│ Resort Hotel │ C         │      601 │  157.86 │     443507.72 │             4.5 │          2.1 │\n",
      "│ Resort Hotel │ H         │      350 │  183.97 │     236640.17 │             3.5 │          1.2 │\n",
      "├──────────────┴───────────┴──────────┴─────────┴───────────────┴─────────────────┴──────────────┤\n",
      "│ 13 rows                                                                              7 columns │\n",
      "└────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6e. Complex CTE pipeline — multi-step analytics\n",
    "# ============================================================\n",
    "# CTEs let you break a complex query into readable, named steps.\n",
    "# Each CTE can reference the previous one.\n",
    "\n",
    "con.sql(\"\"\"\n",
    "    -- Step 1: Base metrics per hotel + room type\n",
    "    WITH room_stats AS (\n",
    "        SELECT\n",
    "            hotel,\n",
    "            room_type,\n",
    "            COUNT(*) AS bookings,\n",
    "            ROUND(AVG(adr), 2) AS avg_adr,\n",
    "            ROUND(SUM(total_revenue), 2) AS total_revenue,\n",
    "            ROUND(AVG(total_nights), 1) AS avg_stay_nights\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY hotel, room_type\n",
    "    ),\n",
    "\n",
    "    -- Step 2: Add hotel-level totals for percentage calculation\n",
    "    hotel_totals AS (\n",
    "        SELECT\n",
    "            hotel,\n",
    "            SUM(bookings) AS hotel_total_bookings\n",
    "        FROM room_stats\n",
    "        GROUP BY hotel\n",
    "    ),\n",
    "\n",
    "    -- Step 3: Combine and compute percentages\n",
    "    enriched AS (\n",
    "        SELECT\n",
    "            r.*,\n",
    "            ROUND(r.bookings * 100.0 / h.hotel_total_bookings, 1) AS pct_of_hotel\n",
    "        FROM room_stats r\n",
    "        JOIN hotel_totals h ON r.hotel = h.hotel\n",
    "    )\n",
    "\n",
    "    -- Final: show top room types by revenue per hotel\n",
    "    SELECT *\n",
    "    FROM enriched\n",
    "    WHERE bookings > 100\n",
    "    ORDER BY hotel, total_revenue DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Export & Persist — Saving Results\n",
    "\n",
    "DuckDB can export query results to **CSV**, **Parquet**, or **JSON**,  \n",
    "and persist the full database to a `.db` file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"data/output\")\n",
    "\n",
    "# ============================================================\n",
    "# 7a. COPY TO — export query results to CSV\n",
    "# ============================================================\n",
    "# COPY (query) TO 'path' (FORMAT, HEADER, DELIMITER)\n",
    "#   FORMAT CSV    → output as CSV\n",
    "#   HEADER true   → include column names as first row\n",
    "#   DELIMITER ',' → column separator\n",
    "\n",
    "csv_export = output_dir / \"hotel_summary_export.csv\"\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT\n",
    "            hotel,\n",
    "            country,\n",
    "            COUNT(*) AS bookings,\n",
    "            ROUND(AVG(adr), 2) AS avg_adr,\n",
    "            ROUND(SUM(total_revenue), 2) AS total_revenue\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY hotel, country\n",
    "        HAVING COUNT(*) > 100\n",
    "        ORDER BY total_revenue DESC\n",
    "    )\n",
    "    TO '{csv_export}'\n",
    "    (FORMAT CSV, HEADER true)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Exported CSV: {csv_export} ({csv_export.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "# Quick peek at the exported file\n",
    "print(\"\\n--- First 5 lines ---\")\n",
    "with csv_export.open() as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7b. COPY TO — export to Parquet\n",
    "# ============================================================\n",
    "\n",
    "parquet_export = output_dir / \"hotel_analytics.parquet\"\n",
    "\n",
    "con.sql(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT\n",
    "            hotel,\n",
    "            year,\n",
    "            month,\n",
    "            room_type,\n",
    "            market_segment,\n",
    "            COUNT(*) AS bookings,\n",
    "            ROUND(AVG(adr), 2) AS avg_adr,\n",
    "            ROUND(SUM(total_revenue), 2) AS total_revenue,\n",
    "            ROUND(AVG(total_nights), 2) AS avg_stay\n",
    "        FROM hotel_clean\n",
    "        WHERE is_canceled = 0\n",
    "        GROUP BY hotel, year, month, room_type, market_segment\n",
    "    )\n",
    "    TO '{parquet_export}'\n",
    "    (FORMAT PARQUET, COMPRESSION ZSTD)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Exported Parquet: {parquet_export} ({parquet_export.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────┐\n",
      "│      name      │\n",
      "│    varchar     │\n",
      "├────────────────┤\n",
      "│ bookings       │\n",
      "│ bookings_clean │\n",
      "└────────────────┘\n",
      "\n",
      "┌────────────────┬────────┐\n",
      "│   table_name   │  rows  │\n",
      "│    varchar     │ int64  │\n",
      "├────────────────┼────────┤\n",
      "│ bookings       │ 119390 │\n",
      "│ bookings_clean │ 117429 │\n",
      "└────────────────┴────────┘\n",
      "\n",
      "\n",
      "Database saved: data/output/hotel_analytics.db (7.3 MB)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7c. Persistent Database — save to a .db file\n",
    "# ============================================================\n",
    "# duckdb.connect('file.db') creates a persistent database.\n",
    "# Tables survive after the connection is closed.\n",
    "# You can reopen it later and all data is still there.\n",
    "\n",
    "db_path = output_dir / \"hotel_analytics.db\"\n",
    "\n",
    "# Open a persistent connection\n",
    "persistent_con = duckdb.connect(str(db_path))\n",
    "\n",
    "# Create tables in the persistent database\n",
    "persistent_con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE bookings AS\n",
    "    SELECT * FROM read_csv_auto('data/hotel_booking.csv')\n",
    "\"\"\")\n",
    "\n",
    "persistent_con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE bookings_clean AS\n",
    "    SELECT\n",
    "        hotel,\n",
    "        country,\n",
    "        CAST(adr AS FLOAT) AS adr,\n",
    "        (stays_in_weekend_nights + stays_in_week_nights) AS total_nights,\n",
    "        adr * (stays_in_weekend_nights + stays_in_week_nights) AS total_revenue,\n",
    "        arrival_date_year AS year,\n",
    "        arrival_date_month AS month,\n",
    "        reserved_room_type AS room_type,\n",
    "        market_segment,\n",
    "        is_canceled\n",
    "    FROM bookings\n",
    "    WHERE adr > 0 AND adr < 5000\n",
    "\"\"\")\n",
    "\n",
    "# Verify\n",
    "persistent_con.sql(\"SHOW TABLES\").show()\n",
    "# SHOW TABLES lists all tables in the database\n",
    "\n",
    "persistent_con.sql(\"\"\"\n",
    "    SELECT\n",
    "        'bookings' AS table_name, COUNT(*) AS rows FROM bookings\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'bookings_clean', COUNT(*) FROM bookings_clean\n",
    "\"\"\").show()\n",
    "\n",
    "# Close the connection (data is saved to disk)\n",
    "persistent_con.close()\n",
    "\n",
    "print(f\"\\nDatabase saved: {db_path} ({db_path.stat().st_size / 1024**2:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬──────────┬─────────┐\n",
      "│    hotel     │ bookings │ avg_adr │\n",
      "│   varchar    │  int64   │ double  │\n",
      "├──────────────┼──────────┼─────────┤\n",
      "│ Resort Hotel │    28270 │   92.93 │\n",
      "│ City Hotel   │    45149 │  108.27 │\n",
      "└──────────────┴──────────┴─────────┘\n",
      "\n",
      "Database reopened, queried, and closed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7d. Reopen persistent database — data is still there!\n",
    "# ============================================================\n",
    "\n",
    "# Reopen the database file\n",
    "reopen_con = duckdb.connect(str(db_path))\n",
    "\n",
    "# Query the previously saved tables\n",
    "reopen_con.sql(\"\"\"\n",
    "    SELECT hotel, COUNT(*) AS bookings, ROUND(AVG(adr), 2) AS avg_adr\n",
    "    FROM bookings_clean\n",
    "    WHERE is_canceled = 0\n",
    "    GROUP BY hotel\n",
    "\"\"\").show()\n",
    "\n",
    "reopen_con.close()\n",
    "print(\"Database reopened, queried, and closed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: close the in-memory connection\n",
    "con.close()\n",
    "print(\"All connections closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "| Feature | How | Why it matters |\n",
    "|---------|-----|---------------|\n",
    "| **In-memory DB** | `duckdb.connect()` | Zero-config analytics, no server |\n",
    "| **CSV ingestion** | `read_csv_auto()` | Auto-detect schema, fast parallel reads |\n",
    "| **Query DataFrames** | `FROM df_name` in SQL | SQL on Pandas with zero copy |\n",
    "| **Query files** | `read_csv_auto('file.csv')`, `read_parquet('file.parquet')` | Analyze files without loading into memory |\n",
    "| **Parquet I/O** | `COPY TO ... (FORMAT PARQUET)` | Convert, compress, and export efficiently |\n",
    "| **Glob patterns** | `read_parquet('data/*.parquet')` | Query partitioned datasets |\n",
    "| **Window functions** | `ROW_NUMBER`, `LAG`, `RANK`, `NTILE`, `SUM OVER` | Rankings, running totals, period comparisons |\n",
    "| **CTEs** | `WITH name AS (...)` | Break complex queries into readable steps |\n",
    "| **Export CSV** | `COPY (...) TO 'file.csv' (FORMAT CSV)` | Share results with non-technical users |\n",
    "| **Persistent DB** | `duckdb.connect('file.db')` | Save tables to disk, reopen later |\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the full Python for Data Engineering learning path:  \n",
    "1. **File Handling** — Pathlib, CSV, JSON, JSONL, generators, binary I/O  \n",
    "2. **Standard Libraries** — datetime, os/sys, logging, collections, glob  \n",
    "3. **Numpy, Pandas & Parquet** — Vectorized processing, transformations, columnar storage  \n",
    "4. **DuckDB SQL Analytics** — In-process OLAP, file querying, window functions, persistence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
